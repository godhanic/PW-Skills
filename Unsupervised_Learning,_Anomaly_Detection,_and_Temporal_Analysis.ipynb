{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm1SCK7xEHO6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised Learning, Anomaly Detection, and Temporal Analysis"
      ],
      "metadata": {
        "id": "XvdmrOkXEUvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: What is Dimensionality Reduction? Why is it important in machine learning?\n",
        "\n",
        "Dimensionality Reduction is a technique used in machine learning to reduce the number of input features (dimensions) while keeping as much useful information as possible.\n",
        "\n",
        "It is the process of transforming high-dimensional data into a lower-dimensional space.\n",
        "Examples of techniques:\n",
        "\n",
        "* PCA (Principal Component Analysis)\n",
        "* t-SNE\n",
        "* UMAP\n",
        "* LDA\n",
        "* Autoencoders\n",
        "\n",
        "The goal is to remove redundant, noisy, or less-important features.\n",
        "\n",
        "\n",
        "\n",
        " Why is Dimensionality Reduction Important?\n",
        "\n",
        "**1. Reduces Overfitting**\n",
        "\n",
        "High-dimensional datasets can contain noisy or irrelevant features.\n",
        "Reducing dimensions helps the model generalize better.\n",
        "\n",
        "**2 Improves Model Performance**\n",
        "\n",
        "Less data → faster training → less memory usage.\n",
        "Algorithms like KNN, SVM, Logistic Regression, and clustering perform much better.\n",
        "\n",
        "**3 Handles the Curse of Dimensionality**\n",
        "\n",
        "When dimensions increase:\n",
        "\n",
        "* distance metrics become less meaningful,\n",
        "* data becomes sparse,\n",
        "* models degrade in accuracy.\n",
        "\n",
        "Reducing dimensionality solves this issue.\n",
        "\n",
        " **4 Makes Visualization Possible**\n",
        "\n",
        "You can visualize:\n",
        "\n",
        "* 2D plots\n",
        "* 3D scatter plots\n",
        "  for understanding dataset structure.\n",
        "\n",
        "t-SNE and UMAP are commonly used for visualization.\n",
        "\n",
        "**5 Removes Multicollinearity**\n",
        "\n",
        "In linear models, PCA can combine correlated features → more stable and robust models.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U-mdU_SkL-cY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2 : Name and briefly describe three common dimensionality reduction techniques.\n",
        "\n",
        "\n",
        "Here are three common dimensionality reduction techniques with brief descriptions:\n",
        "\n",
        "\n",
        "\n",
        "**1 Principal Component Analysis (PCA)**\n",
        "\n",
        "* A **linear** dimensionality reduction method.\n",
        "* Converts original features into new uncorrelated features called **principal components**.\n",
        "* These components capture the maximum variance in the data.\n",
        "* Commonly used for compression, visualization, and removing multicollinearity.\n",
        "\n",
        "\n",
        " **2 t-SNE (t-Distributed Stochastic Neighbor Embedding)**\n",
        "\n",
        "* A **non-linear** technique mainly used for **visualization**.\n",
        "* Preserves **local structure** (points that are close stay close).\n",
        "* Maps high-dimensional data into **2D or 3D**.\n",
        "* Works very well for visualizing clusters (e.g., MNIST digits).\n",
        "\n",
        "\n",
        "\n",
        "**3 LDA (Linear Discriminant Analysis)**\n",
        "\n",
        "* A **supervised** dimensionality reduction method.\n",
        "* Maximizes separability between classes by finding the feature space that best separates them.\n",
        "* Works well for classification tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "KKskrPhrPt-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3 : What is clustering in unsupervised learning? Mention three popular clustering algorithms.\n",
        "\n",
        "\n",
        "**Clustering** in unsupervised learning is the process of **grouping similar data points** into clusters based on patterns or similarity—**without using labeled data**.\n",
        "The goal is to ensure that:\n",
        "\n",
        "* Points **within the same cluster** are very similar\n",
        "* Points **in different clusters** are dissimilar\n",
        "\n",
        "Clustering is widely used in customer segmentation, anomaly detection, image grouping, etc.\n",
        "\n",
        "\n",
        "\n",
        "✔ **Three Popular Clustering Algorithms**\n",
        "\n",
        "**1 K-Means Clustering**\n",
        "\n",
        "* Divides data into *k* clusters based on minimizing within-cluster variance.\n",
        "* Uses centroids to represent each cluster.\n",
        "* Fast and widely used but assumes spherical clusters.\n",
        "\n",
        "**2 Hierarchical Clustering**\n",
        "\n",
        "* Builds a cluster tree (dendrogram).\n",
        "* Two types:\n",
        "\n",
        "  * **Agglomerative** (bottom-up)\n",
        "  * **Divisive** (top-down)\n",
        "* No need to predefine the number of clusters initially.\n",
        "\n",
        " **3 DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**\n",
        "\n",
        "* Groups points based on density (dense regions → clusters).\n",
        "* Can find clusters of any shape.\n",
        "* Automatically identifies **noise/outliers**.\n",
        "* Does not require specifying the number of clusters in advance.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W5rXAtJ6QgN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4 : Explain the concept of anomaly detection and its significance\n",
        "\n",
        "Anomaly Detection is the process of identifying unusual patterns or data points that do not fit the expected behavior of a dataset.\n",
        "These unusual points are called:\n",
        "\n",
        "* **Anomalies**\n",
        "* **Outliers**\n",
        "* **Deviations**\n",
        "* **Irregularities**\n",
        "\n",
        "\n",
        "\n",
        " **What is the Concept of Anomaly Detection?**\n",
        "\n",
        "Anomaly detection involves analyzing data to find instances that are:\n",
        "\n",
        "* Rare\n",
        "* Unexpected\n",
        "* Suspicious\n",
        "* Significantly different from the majority\n",
        "\n",
        "It is typically done using **unsupervised learning**, because in real-world scenarios, labels for anomalies are rarely available.\n",
        "\n",
        "Common approaches:\n",
        "\n",
        "* **Statistical methods** (e.g., Z-score, IQR)\n",
        "* **Clustering-based methods** (e.g., DBSCAN)\n",
        "* **Distance-based methods** (e.g., k-NN)\n",
        "* **Machine learning models** (e.g., Isolation Forest, Autoencoders)\n",
        "\n",
        "**Significance of Anomaly Detection**\n",
        "\n",
        "**1  Fraud Detection**\n",
        "\n",
        "Identifies unusual credit card transactions, insurance fraud, etc.\n",
        "\n",
        " **2  Network Security**\n",
        "\n",
        "Detects unexpected patterns such as intrusion attempts, malware, or unusual network traffic.\n",
        "\n",
        "**3  Manufacturing and IoT**\n",
        "\n",
        "Finds faulty sensor readings or machine failures before breakdown (predictive maintenance).\n",
        "\n",
        " **4 Healthcare**\n",
        "\n",
        "Identifies abnormal patient vitals or unusual medical test results.\n",
        "\n",
        " **5 Monitoring Systems**\n",
        "\n",
        "Detects sudden changes in server performance, website traffic, or user behavior.\n",
        "\n",
        "**6 Data Cleaning**\n",
        "\n",
        "Helps remove erroneous entries to improve model performance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G2LPE3q7N7Cu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5 : List and briefly describe three types of anomaly detection techniques.\n",
        "\n",
        "\n",
        "Here are **three important types of anomaly detection techniques** with brief descriptions:\n",
        "\n",
        " **1 Statistical Methods**\n",
        "\n",
        "These methods assume normal data follows a known statistical distribution (e.g., Gaussian).\n",
        "Anomalies are points that deviate significantly from this distribution.\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "* Z-score\n",
        "* Median Absolute Deviation (MAD)\n",
        "* Interquartile Range (IQR)\n",
        "\n",
        "**Use case:** Simple datasets, numerical data, data quality checks.\n",
        "\n",
        "**2 Clustering-Based Methods**\n",
        "\n",
        "These assume that normal points belong to dense clusters, while anomalies lie far from clusters or form very small clusters.\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "* DBSCAN (noise points = anomalies)\n",
        "* K-Means (points far from cluster centers can be anomalies)\n",
        "\n",
        "**Use case:** Detecting unusual behavior in unlabeled data.\n",
        "\n",
        " **3 Machine Learning–Based Methods**\n",
        "\n",
        "These methods learn patterns in the data and identify points that do not follow learned behavior.\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "* **Isolation Forest:** isolates anomalies by random partitioning\n",
        "* **One-Class SVM:** learns a boundary around normal data\n",
        "* **Autoencoders:** anomalies have high reconstruction error\n",
        "\n",
        "**Use case:** High-dimensional data, fraud detection, network security.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9jvXEJjeOb_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6 : What is time series analysis? Mention two key components of time series data.\n",
        "\n",
        "Time Series Analysis is the process of studying data points collected or recorded over time (daily, monthly, yearly, etc.) to understand patterns, trends, and to make forecasts.\n",
        "It focuses on how a variable changes over time and helps in predicting future values.\n",
        "\n",
        "Examples: stock prices, weather data, sales numbers, sensor readings.\n",
        "\n",
        "\n",
        " **Two Key Components of Time Series Data**\n",
        "\n",
        " **1 Trend**\n",
        "\n",
        "A long-term upward or downward movement in the data.\n",
        "Example: A company’s sales increasing steadily over several years.\n",
        "\n",
        " **2 Seasonality**\n",
        "\n",
        "A repeating pattern at regular time intervals.\n",
        "Example: Online shopping spikes during festivals or weekends.\n",
        "\n",
        "\n",
        "\n",
        "(Other components include **cyclic patterns** and **random noise**, if you need more details.)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QiLQ4HicOxL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 7 : Describe the difference between seasonality and cyclic behavior in time series.\n",
        "\n",
        "\n",
        "Here’s the difference between seasonality and cyclic behavior in time series, explained clearly:\n",
        "\n",
        " **✔ Seasonality**\n",
        "\n",
        "* Refers to **regular, predictable patterns** that repeat at **fixed time intervals**.\n",
        "* The period of repetition is **known and consistent** (e.g., daily, weekly, monthly, yearly).\n",
        "* Driven by **calendar-related** or **environmental** factors.\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "* Higher ice-cream sales every summer\n",
        "* Increased electricity usage every evening\n",
        "* More shopping during weekends or festivals\n",
        "\n",
        "**Key point:** Seasonality has **fixed and known periodicity**.\n",
        "\n",
        "**✔ Cyclic Behavior**\n",
        "\n",
        "* Refers to long-term **up-and-down movements** that are **not fixed or regular**.\n",
        "* The duration (cycle length) is **variable and unpredictable**.\n",
        "* Often influenced by **economic or business cycles**, not the calendar.\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "* Economic boom and recession cycles\n",
        "* Fluctuations in real estate markets\n",
        "* Long-term business growth and decline patterns\n",
        "\n",
        "**Key point:** Cycles are **irregular**, with **no fixed time interval**.\n",
        "\n",
        "** Summary Table**\n",
        "\n",
        "| Feature  | Seasonality          | Cyclic Behavior              |\n",
        "| -------- | -------------------- | ---------------------------- |\n",
        "| Repeats? | Yes                  | Yes                          |\n",
        "| Interval | **Fixed, known**     | **Variable, unknown**        |\n",
        "| Cause    | Calendar/environment | Economic or long-term trends |\n",
        "| Duration | Short (days, months) | Long (years)                 |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NeN2i3wGPOBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 8: Write Python code to perform K-means clustering on a sample dataset.\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Sample dataset (2D points)\n",
        "data = np.array([\n",
        "    [1, 2],\n",
        "    [1, 4],\n",
        "    [1, 0],\n",
        "    [10, 2],\n",
        "    [10, 4],\n",
        "    [10, 0]\n",
        "])\n",
        "\n",
        "# Create and fit K-Means model\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "kmeans.fit(data)\n",
        "\n",
        "# Print cluster centers\n",
        "print(\"Cluster Centers:\")\n",
        "print(kmeans.cluster_centers_)\n",
        "\n",
        "# Print predicted cluster labels\n",
        "print(\"\\nCluster Labels:\")\n",
        "print(kmeans.labels_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc2c3e8-e97f-4657-88c9-812d306715d4",
        "id": "M4Flv8JXWNzJ"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers:\n",
            "[[ 1.  2.]\n",
            " [10.  2.]]\n",
            "\n",
            "Cluster Labels:\n",
            "[0 0 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 9: What is inheritance in OOP? Provide a simple example in Python\n",
        "\n",
        "# inheritance in Object-Oriented Programming (OOP) is a mechanism that allows one class (child/subclass) to acquire the properties and methods of another class (parent/superclass).\n",
        "# It promotes code reusability, extensibility, and clean structure.\n",
        "\n",
        "# Parent class\n",
        "class Animal:\n",
        "    def sound(self):\n",
        "        return \"Some generic sound\"\n",
        "\n",
        "# Child class inheriting from Animal\n",
        "class Dog(Animal):\n",
        "    def sound(self):\n",
        "        return \"Bark\"\n",
        "\n",
        "# Using the classes\n",
        "a = Animal()\n",
        "d = Dog()\n",
        "\n",
        "print(a.sound())  # Output: Some generic sound\n",
        "print(d.sound())  # Output: Bark\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c6e1f4-bca0-4b05-dde7-a1cf67ec3c3a",
        "id": "Wi4PXiOkQrs1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some generic sound\n",
            "Bark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 10: How can time series analysis be used for anomaly detection?\n",
        "\n",
        "Time series analysis can be used for anomaly detection by examining how values change over time and identifying points that deviate from expected patterns such as trend, seasonality, or normal behavior.\n",
        "\n",
        "Here’s how it works:\n",
        "\n",
        " **How Time Series Helps in Anomaly Detection**\n",
        "\n",
        " **1 Detecting Sudden Spikes or Drops**\n",
        "\n",
        "Time series models learn the usual behavior of data.\n",
        "When a value jumps too high or drops too low unexpectedly, it is flagged as an anomaly.\n",
        "\n",
        "**Example:**\n",
        "A sudden drop in website traffic might indicate a system outage.\n",
        "\n",
        " **2 Identifying Seasonality Deviations**\n",
        "\n",
        "If data normally follows seasonal patterns, any deviation from this pattern can signal an anomaly.\n",
        "\n",
        "**Example:**\n",
        "Electricity usage always rises in the evening — if it doesn’t, something may be wrong.\n",
        "\n",
        " **3 Forecast-Based Anomaly Detection**\n",
        "\n",
        "A model predicts the next expected values.\n",
        "If the actual value differs from the forecast beyond a threshold, it is considered an anomaly.\n",
        "\n",
        "**Methods:**\n",
        "\n",
        "* ARIMA\n",
        "* SARIMA\n",
        "* LSTM models\n",
        "* Prophet\n",
        "\n",
        "**Example:**\n",
        "A predicted sales value is 500 units, but actual sales are 900 → anomaly.\n",
        "\n",
        " **4 Residual Analysis**\n",
        "\n",
        "Residual = actual value – predicted value\n",
        "If residuals are unusually large, the data point is anomalous.\n",
        "\n",
        " **5 Moving Statistics (Simple Approaches)**\n",
        "\n",
        "Calculate metrics like:\n",
        "\n",
        "* Rolling mean\n",
        "* Rolling standard deviation\n",
        "\n",
        "Points outside normal ranges are anomalies.\n",
        "\n",
        " **Summary**\n",
        "\n",
        "Time series anomaly detection works by:\n",
        "\n",
        "* Learning normal patterns\n",
        "* Predicting expected behavior\n",
        "* Flagging values that deviate significantly\n",
        "\n",
        "This is widely used in:\n",
        "\n",
        "* Fraud detection\n",
        "* Server or network monitoring\n",
        "* Industrial sensors (IoT)\n",
        "* Healthcare signals\n",
        "* Financial markets\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9gvvzaFTQfS6"
      }
    }
  ]
}